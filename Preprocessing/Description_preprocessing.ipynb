{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNVbReqoCQvDkzypT2AVW/J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Connecting google drive"],"metadata":{"id":"g_o5K3CgPv0l"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"klbWNFejQUUE","executionInfo":{"status":"ok","timestamp":1709522175005,"user_tz":-330,"elapsed":23575,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}},"outputId":"beda381d-2bd3-46a0-c55c-04d28d495dc6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Connecting kaggle"],"metadata":{"id":"rcTCo5r-Qeg2"}},{"cell_type":"code","source":["!pip install -q kaggle"],"metadata":{"id":"YsNddCyQQVKW","executionInfo":{"status":"ok","timestamp":1709522181830,"user_tz":-330,"elapsed":6837,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":92},"id":"GqG4_WvdQi1t","executionInfo":{"status":"ok","timestamp":1709522195431,"user_tz":-330,"elapsed":13637,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}},"outputId":"37b7ae15-8026-4998-b3af-4e7ebf02fae1"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-0877b7f4-ba96-4667-a738-49ab12a7610a\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-0877b7f4-ba96-4667-a738-49ab12a7610a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n"]},{"output_type":"execute_result","data":{"text/plain":["{'kaggle.json': b'{\"username\":\"arbazkhancs\",\"key\":\"140450ae4ad01edb47d18c912d681ad3\"}'}"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Create A Kaggle Folder\n","! mkdir ~/.kaggle"],"metadata":{"id":"wgVGrSadQsLw","executionInfo":{"status":"ok","timestamp":1709522195989,"user_tz":-330,"elapsed":15,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Copy the kaggle.json file to the above folder\n","! cp kaggle.json ~/.kaggle/"],"metadata":{"id":"Y_3ldswaQ20H","executionInfo":{"status":"ok","timestamp":1709522196574,"user_tz":-330,"elapsed":8,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Permission for the json to act\n","! chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"PyYFjSG0Q5Sj","executionInfo":{"status":"ok","timestamp":1709522197363,"user_tz":-330,"elapsed":794,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# to list all kaggle datasets\n","! kaggle datasets list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tuU3ZWzAQ7S5","executionInfo":{"status":"ok","timestamp":1709522198086,"user_tz":-330,"elapsed":739,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}},"outputId":"b13e9a1b-a6fd-4a1d-8ce5-1b8b6ffa1c14"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.7 / client 1.5.16)\n","ref                                                          title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n","-----------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n","syedanwarafridi/vehicle-sales-data                           Vehicle Sales Data                                  19MB  2024-02-21 20:16:17           5928         93  1.0              \n","tarunrm09/climate-change-indicators                          Climate change Indicators                           34KB  2024-02-22 08:53:54           2777         67  1.0              \n","nelgiriyewithana/apple-quality                               Apple Quality                                      170KB  2024-01-11 14:31:07          24953        531  1.0              \n","devi5723/e-commerce-cosmetics-dataset                        E-commerce Cosmetic Products                         1MB  2024-02-28 14:46:12            839         27  0.9411765        \n","sazidthe1/world-gdp-growth                                   World GDP Growth                                    14KB  2024-02-25 11:37:58            940         22  1.0              \n","kanchana1990/spotifys-long-hits-2014-2024                    Spotify's Long Hits (2014-2024) 🎶                   38KB  2024-02-23 12:39:02           2030         48  1.0              \n","raphaelmanayon/temperature-and-ice-cream-sales               Temperature and Ice Cream Sales                      1KB  2024-02-19 18:53:52           1936         31  0.9411765        \n","mikhail1681/walmart-sales                                    Walmart Sales                                      122KB  2024-02-13 17:35:56           5199         80  1.0              \n","nelgiriyewithana/emotions                                    Emotions                                            16MB  2024-02-05 16:01:39           5014        152  1.0              \n","xontoloyo/data-penjualan-zara                                ZARA Sales                                          17KB  2024-02-27 05:37:53           1457         35  0.9411765        \n","nbroad/gemma-rewrite-nbroad                                  gemma-rewrite-nbroad                                 8MB  2024-03-03 04:52:39            201         39  1.0              \n","antaesterlin/walmart-commerce-data                           Walmart commerce data                               41KB  2024-02-20 23:48:17           1800         31  0.9411765        \n","kanchana1990/best-buy-2024-windows-laptops                   Best Buy 2024 💻 Windows Laptops                     27KB  2024-02-17 17:11:17           1105         30  1.0              \n","dansbecker/melbourne-housing-snapshot                        Melbourne Housing Snapshot                         451KB  2018-06-05 12:52:24         140356       1442  0.7058824        \n","willianoliveiragibin/drug-overdose-death                     Drug overdose death                                 582B  2024-02-22 20:36:47           1745         39  1.0              \n","harshitstark/covid-19-global-statistics-dataset              COVID-19 Global Statistics Dataset                  10KB  2024-02-21 19:05:14           2027         38  1.0              \n","kapturovalexander/maang-share-prices-till-february-2024      📈💸 MAANG share prices till February 2024 😎🧑‍💻      624KB  2024-03-01 10:53:27            441         26  1.0              \n","verracodeguacas/pii-deberta-models                           PII deberta models                                  16GB  2024-02-28 01:54:01            337         30  0.875            \n","tarunrm09/indian-cuisine-based-rda-diet-recommendation-data  Indian cuisine based RDA diet recommendation data    3KB  2024-02-21 07:38:46            599         25  1.0              \n","mikhail1681/mcdonalds-financial-statements-2002-2022         McDonald's financial statements (2002-2022)          1KB  2024-02-23 16:28:24            985         35  1.0              \n"]}]},{"cell_type":"markdown","source":["# Downloading Dataset"],"metadata":{"id":"YMGpqBxNRHo6"}},{"cell_type":"code","source":["! kaggle datasets download -d adityajn105/flickr8k"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfAIaGL6Q9Lj","executionInfo":{"status":"ok","timestamp":1709522255892,"user_tz":-330,"elapsed":11224,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}},"outputId":"40f36626-1d04-4be8-800b-047cd08bb983"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading flickr8k.zip to /content\n"," 99% 1.03G/1.04G [00:10<00:00, 138MB/s]\n","100% 1.04G/1.04G [00:10<00:00, 107MB/s]\n"]}]},{"cell_type":"code","source":["# unzip the downloaded file\n","! unzip flickr8k.zip"],"metadata":{"id":"89hcfC84RAIL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Importing neccessary librarys"],"metadata":{"id":"vj6brERsRPV5"}},{"cell_type":"code","source":["from os import listdir\n","import numpy as np\n","from tqdm import tqdm\n","import pickle\n","\n","from keras.preprocessing.text import Tokenizer\n","from keras.utils import pad_sequences"],"metadata":{"id":"GHdNkCVaRDRK","executionInfo":{"status":"ok","timestamp":1709524199104,"user_tz":-330,"elapsed":12,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}}},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":["# Load Descriptions"],"metadata":{"id":"XeROZ5J4SZeL"}},{"cell_type":"code","source":["with open('captions.txt', 'r') as f:\n","  next(f) # continue the header\n","  captions_doc = f.read()"],"metadata":{"id":"uJa7tCLvSAxL","executionInfo":{"status":"ok","timestamp":1709522304118,"user_tz":-330,"elapsed":460,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["captions_doc.split('\\n')[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"YsZ1JzpMS421","executionInfo":{"status":"ok","timestamp":1709522354169,"user_tz":-330,"elapsed":515,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}},"outputId":"3ae18488-a96a-4e95-9a5b-9c4760cc703a"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1000268201_693b08cb0e.jpg,A child in a pink dress is climbing up a set of stairs in an entry way .'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["# Mapping the image_id with it's Captions"],"metadata":{"id":"OjJ5_OC1TCnO"}},{"cell_type":"code","source":["def load_descption_to_dictionary(descriptions):\n","  map = {}\n","  for line in tqdm(descriptions.split(\"\\n\")):\n","    # description shpuld have atleast 2 words\n","    if len(line) < 2:\n","      continue\n","\n","    # extract image_id, image descripton\n","    image_id, image_desc = line.split(\",\")[0], line.split(\",\")[1:]\n","\n","    # extract image_id not it's extension\n","    image_id = image_id.split(\".\")[0]\n","\n","    # Convert the caption list to a string by joining its elements\n","    caption = ' '.join(image_desc)\n","\n","    # Create a list if the image ID is not already in the mapping dictionary\n","    if image_id not in map:\n","      map[image_id] = []\n","\n","    # store the image_id and it's caption\n","    map[image_id].append(caption)\n","\n","  return map"],"metadata":{"id":"dlf3ryYgS61n","executionInfo":{"status":"ok","timestamp":1709522879043,"user_tz":-330,"elapsed":828,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["captions_dict = load_descption_to_dictionary(captions_doc)\n","captions_dict[\"1000268201_693b08cb0e\"], len(captions_dict)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V2ALfMDuVTGk","executionInfo":{"status":"ok","timestamp":1709522879507,"user_tz":-330,"elapsed":7,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}},"outputId":"2f106db7-d5dd-4f35-fb08-a4463f958fec"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 40456/40456 [00:00<00:00, 515547.61it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["(['A child in a pink dress is climbing up a set of stairs in an entry way .',\n","  'A girl going into a wooden building .',\n","  'A little girl climbing into a wooden playhouse .',\n","  'A little girl climbing the stairs to her playhouse .',\n","  'A little girl in a pink dress going into a wooden cabin .'],\n"," 8091)"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["# Cleaning Captions"],"metadata":{"id":"Gh7fg41MXTs8"}},{"cell_type":"code","source":["def clean_captions(captions_dict):\n","  for image, captions in tqdm(captions_dict.items()):\n","    for i in range(len(captions)):\n","      # Load captions one by one\n","      caption = captions[i]\n","\n","      # Convert the caption to lowercase\n","      caption = caption.lower()\n","\n","      # delete digits, special chars, etc.,\n","      caption = caption.replace('[^A-Za-z]', '')\n","\n","      # delete additional spaces\n","      caption = caption.replace('\\s+', ' ')\n","\n","      # add start and end tags to the caption and remove word < length 2\n","      caption = '<startseq> ' + \" \".join([word for word in caption.split() if len(word)>1]) + ' <endseq>'\n","      captions[i] = caption\n","\n","  return"],"metadata":{"id":"iqmzuyngViK5","executionInfo":{"status":"ok","timestamp":1709522882178,"user_tz":-330,"elapsed":6,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["print(\"Before Cleaning\")\n","captions_dict[\"1000268201_693b08cb0e\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XdwRZZgHY55O","executionInfo":{"status":"ok","timestamp":1709522884264,"user_tz":-330,"elapsed":5,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}},"outputId":"403a00e4-b876-4d0e-bf00-16ca7e70c3a0"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Before Cleaning\n"]},{"output_type":"execute_result","data":{"text/plain":["['A child in a pink dress is climbing up a set of stairs in an entry way .',\n"," 'A girl going into a wooden building .',\n"," 'A little girl climbing into a wooden playhouse .',\n"," 'A little girl climbing the stairs to her playhouse .',\n"," 'A little girl in a pink dress going into a wooden cabin .']"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["clean_captions(captions_dict)\n","print(\"\\nAfter Cleaning\")\n","captions_dict[\"1000268201_693b08cb0e\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LpY7TOhTZYGl","executionInfo":{"status":"ok","timestamp":1709522887756,"user_tz":-330,"elapsed":464,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}},"outputId":"537d589a-75df-40dc-fa8a-1a43bf66c628"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 8091/8091 [00:00<00:00, 33187.05it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","After Cleaning\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["['<startseq> child in pink dress is climbing up set of stairs in an entry way <endseq>',\n"," '<startseq> girl going into wooden building <endseq>',\n"," '<startseq> little girl climbing into wooden playhouse <endseq>',\n"," '<startseq> little girl climbing the stairs to her playhouse <endseq>',\n"," '<startseq> little girl in pink dress going into wooden cabin <endseq>']"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["# Creating list of captions"],"metadata":{"id":"ZzQI7_YHZ0Xh"}},{"cell_type":"code","source":["def create_caption_list(captions_dict):\n","  all_captions = []\n","  for imageId in tqdm(captions_dict):\n","    for caption in captions_dict[imageId]:\n","      all_captions.append(caption)\n","  return all_captions"],"metadata":{"id":"10O5BYaIZurn","executionInfo":{"status":"ok","timestamp":1709523260132,"user_tz":-330,"elapsed":9,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["all_captions = create_caption_list(captions_dict)\n","all_captions[:10], len(all_captions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QBQOy35EatdC","executionInfo":{"status":"ok","timestamp":1709523262619,"user_tz":-330,"elapsed":10,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}},"outputId":"6b2a5a7b-3648-4e70-f134-efe5614cdb08"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 8091/8091 [00:00<00:00, 525668.60it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["(['<startseq> child in pink dress is climbing up set of stairs in an entry way <endseq>',\n","  '<startseq> girl going into wooden building <endseq>',\n","  '<startseq> little girl climbing into wooden playhouse <endseq>',\n","  '<startseq> little girl climbing the stairs to her playhouse <endseq>',\n","  '<startseq> little girl in pink dress going into wooden cabin <endseq>',\n","  '<startseq> black dog and spotted dog are fighting <endseq>',\n","  '<startseq> black dog and tri-colored dog playing with each other on the road <endseq>',\n","  '<startseq> black dog and white dog with brown spots are staring at each other in the street <endseq>',\n","  '<startseq> two dogs of different breeds looking at each other on the road <endseq>',\n","  '<startseq> two dogs on pavement moving toward each other <endseq>'],\n"," 40455)"]},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["# Create Tokenizer"],"metadata":{"id":"sNdxRgF4ceBb"}},{"cell_type":"code","source":["def create_tokenizer(all_captions):\n","  tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(all_captions)\n","  # print(tokenizer.word_index)\n","  return tokenizer"],"metadata":{"id":"ym-gZXqCazE9","executionInfo":{"status":"ok","timestamp":1709523696194,"user_tz":-330,"elapsed":7,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["tokenizer = create_tokenizer(all_captions)"],"metadata":{"id":"QIYlsAYVio4c","executionInfo":{"status":"ok","timestamp":1709523702927,"user_tz":-330,"elapsed":1212,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["vocab_size = len(tokenizer.word_index) + 1\n","max_len = max(len(caption.split())for caption in all_captions)\n","\n","vocab_size, max_len"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WakLxUaXirYA","executionInfo":{"status":"ok","timestamp":1709523801824,"user_tz":-330,"elapsed":11,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}},"outputId":"afff6733-a51a-4eda-cfc8-4ed57c8dbe1b"},"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(8485, 35)"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["# Train Test Split"],"metadata":{"id":"A9090aBSkKwq"}},{"cell_type":"code","source":["imageIds = list(captions_dict.keys())\n","split = int(len(imageIds) * 0.90)\n","train = imageIds[:split]\n","test = imageIds[split:]"],"metadata":{"id":"WfjvJqpsjxHQ","executionInfo":{"status":"ok","timestamp":1709524073783,"user_tz":-330,"elapsed":16,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["# Save"],"metadata":{"id":"kxnm3LeslM66"}},{"cell_type":"code","source":["with open(\"/content/drive/MyDrive/Colab Notebooks/Image-Captioning Project/Preprocessing/tokenizer.pkl\", \"wb\") as f:\n","  pickle.dump(tokenizer, f)\n","\n","with open(\"/content/drive/MyDrive/Colab Notebooks/Image-Captioning Project/Preprocessing/captions_dict.pkl\", \"wb\") as f:\n","  pickle.dump(captions_dict, f)\n","\n","with open(\"/content/drive/MyDrive/Colab Notebooks/Image-Captioning Project/Preprocessing/all_captions.pkl\", \"wb\") as f:\n","  pickle.dump(all_captions, f)"],"metadata":{"id":"0TEeEbs1kqv_","executionInfo":{"status":"ok","timestamp":1709525677159,"user_tz":-330,"elapsed":8,"user":{"displayName":"Arbaz Khan","userId":"05992317790063661793"}}},"execution_count":45,"outputs":[]}]}